{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_tensor(video_path: str,\n",
    "                    greyscale: bool = False,\n",
    "                    dtype: torch.dtype = torch.float32):\n",
    "    \"\"\"\n",
    "    Load a video from a file and convert it to a tensor that is greyscale\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video_path : str\n",
    "        The path to the video file\n",
    "    greyscale : bool\n",
    "        Whether to convert the video to greyscale\n",
    "    dtype : torch.dtype\n",
    "        The datatype to convert the video to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    video : torch.Tensor\n",
    "        The video as a tensor\n",
    "    \"\"\"\n",
    "    video, audio, info = io.read_video(video_path, pts_unit='sec')\n",
    "\n",
    "    if not greyscale:\n",
    "        video = video.to(dtype)\n",
    "        video = torch.mean(video, dim=3, keepdim=False)\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 720, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_path = './videos/Ball_Bounce_Vid.mp4'\n",
    "video_tensor = video_to_tensor(video_path,\n",
    "                               greyscale=False,\n",
    "                               dtype=torch.float32)\n",
    "print(video_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pretend that there are two camera perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_camera_videos_to_tensor(video_path1: str,\n",
    "                                video_path2: str,\n",
    "                                greyscale: bool = False,\n",
    "                                dtype: torch.dtype = torch.float32):\n",
    "    \"\"\"\n",
    "    Load two videos from files and convert them to a tensor that is greyscale\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    video_path1 : str\n",
    "        The path to the first video file\n",
    "    video_path2 : str\n",
    "        The path to the second video file\n",
    "    greyscale : bool\n",
    "        Whether to convert the videos to greyscale\n",
    "    dtype : torch.dtype\n",
    "        The datatype to convert the videos to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    video : torch.Tensor\n",
    "        The combined videos as a tensor\n",
    "    \"\"\"\n",
    "    video1 = video_to_tensor(video_path1, greyscale, dtype)\n",
    "    video2 = video_to_tensor(video_path2, greyscale, dtype)\n",
    "\n",
    "    # Match the number of frames in the two videos to the minimum number of frames\n",
    "    min_frames = min(video1.shape[0], video2.shape[0])\n",
    "    video1 = video1[:min_frames]\n",
    "    video2 = video2[:min_frames]\n",
    "\n",
    "    # Now combine the two videos into a single tensor, where the first dimension are the frames and the second dimension are the two videos\n",
    "    video1 = video1.unsqueeze(1)\n",
    "    video2 = video2.unsqueeze(1)\n",
    "\n",
    "    video = torch.cat((video1, video2), dim=1)\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 2, 720, 1280])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "video_path1 = './videos/Ball_Bounce_Vid.mp4'\n",
    "video_path2 = './videos/Ball_Roll_Vid.mp4'\n",
    "video_tensor = two_camera_videos_to_tensor(video_path1,\n",
    "                                           video_path2,\n",
    "                                           greyscale=False,\n",
    "                                           dtype=torch.float32)\n",
    "print(video_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
