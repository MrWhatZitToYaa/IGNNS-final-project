{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from bcnf.model.feature_network import FeatureNetwork\n",
    "\n",
    "\n",
    "class ConditionalInvertibleLayer(nn.Module):\n",
    "    log_det_J: float | torch.Tensor | None\n",
    "    n_conditions: int\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, log_det_J: bool = False) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def inverse(self, z: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        pass\n",
    "\n",
    "\n",
    "class ConditionalNestedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, n_conditions: int, dropout: float = 0.2) -> None:\n",
    "        super(ConditionalNestedNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.n_conditions = n_conditions\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size + n_conditions, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, output_size * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        if self.n_conditions > 0:\n",
    "            # Concatenate the input with the condition\n",
    "            x = torch.cat([x, y], dim=1)\n",
    "\n",
    "        # Get the translation coefficients t and the scale coefficients s from the neural network\n",
    "        t, s = self.layers(x).chunk(2, dim=1)\n",
    "\n",
    "        # Return the coefficients\n",
    "        return t, torch.tanh(s)\n",
    "\n",
    "\n",
    "class ConditionalAffineCouplingLayer(ConditionalInvertibleLayer):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_conditions: int, dropout: float = 0.2) -> None:\n",
    "        super(ConditionalAffineCouplingLayer, self).__init__()\n",
    "\n",
    "        self.n_conditions = n_conditions\n",
    "        self.log_det_J = None\n",
    "\n",
    "        # Create the nested neural network\n",
    "        self.nn = ConditionalNestedNeuralNetwork(\n",
    "            input_size=np.ceil(input_size / 2).astype(int),\n",
    "            output_size=np.floor(input_size / 2).astype(int),\n",
    "            hidden_size=hidden_size,\n",
    "            n_conditions=n_conditions,\n",
    "            dropout=dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, log_det_J: bool = False) -> torch.Tensor:\n",
    "        # Split the input into two halves\n",
    "        x_a, x_b = x.chunk(2, dim=1)\n",
    "\n",
    "        # Get the coefficients from the neural network\n",
    "        t, log_s = self.nn.forward(x_a, y)\n",
    "\n",
    "        # Apply the transformation\n",
    "        z_a = x_a  # skip connection\n",
    "        z_b = torch.exp(log_s) * x_b + t  # affine transformation\n",
    "\n",
    "        # Calculate the log determinant of the Jacobian\n",
    "        if log_det_J:\n",
    "            self.log_det_J = log_s.sum(dim=1)\n",
    "\n",
    "        # Return the output\n",
    "        return torch.cat([z_a, z_b], dim=1)\n",
    "\n",
    "    def inverse(self, z: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # Split the input into two halves\n",
    "        z_a, z_b = z.chunk(2, dim=1)\n",
    "\n",
    "        # Get the coefficients from the neural network\n",
    "        t, log_s = self.nn.forward(z_a, y)\n",
    "\n",
    "        # Apply the inverse transformation\n",
    "        x_a = z_a\n",
    "        x_b = (z_b - t) * torch.exp(- log_s)\n",
    "\n",
    "        # Return the output\n",
    "        return torch.cat([x_a, x_b], dim=1)\n",
    "\n",
    "\n",
    "class OrthonormalTransformation(ConditionalInvertibleLayer):\n",
    "    def __init__(self, input_size: int) -> None:\n",
    "        super(OrthonormalTransformation, self).__init__()\n",
    "\n",
    "        self.log_det_J = 0\n",
    "\n",
    "        # Create the random orthonormal matrix via QR decomposition\n",
    "        self.orthonormal_matrix = nn.Parameter(torch.linalg.qr(torch.randn(input_size, input_size))[0], requires_grad=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, log_det_J: bool = False) -> torch.Tensor:\n",
    "        # Apply the transformation\n",
    "        return x @ self.orthonormal_matrix\n",
    "\n",
    "    def inverse(self, z: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply the inverse transformation\n",
    "        return z @ self.orthonormal_matrix.T\n",
    "\n",
    "\n",
    "class CondRealNVP(ConditionalInvertibleLayer):\n",
    "    def __init__(self, input_size: int, hidden_size: int, n_epochs: int, n_conditions: int, feature_network: FeatureNetwork | None, dropout: float = 0.2, device: str = \"cpu\"):\n",
    "        super(CondRealNVP, self).__init__()\n",
    "\n",
    "        if n_conditions == 0 or feature_network is None:\n",
    "            self.h = nn.Identity()\n",
    "        else:\n",
    "            self.h = feature_network\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_conditions = n_conditions\n",
    "        self.device = device\n",
    "\n",
    "        self.layers = self._build_network()\n",
    "\n",
    "        self.log_det_J: float | None = None\n",
    "\n",
    "    def _build_network(self) -> nn.ModuleList:\n",
    "        # Create the network\n",
    "        layers: list[ConditionalInvertibleLayer] = []\n",
    "        for _ in range(self.n_epochs - 1):\n",
    "            layers.append(ConditionalAffineCouplingLayer(self.input_size, self.hidden_size, self.n_conditions, dropout=0.2))\n",
    "            layers.append(OrthonormalTransformation(self.input_size))\n",
    "\n",
    "        # Add the final affine coupling layer\n",
    "        layers.append(ConditionalAffineCouplingLayer(self.input_size, self.hidden_size, self.n_conditions, dropout=0.2))\n",
    "\n",
    "        return nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, log_det_J: bool = False) -> torch.Tensor:\n",
    "        # Apply the feature network to y\n",
    "        y = self.h(y)\n",
    "\n",
    "        # Apply the network\n",
    "\n",
    "        if log_det_J:\n",
    "            self.log_det_J = 0\n",
    "\n",
    "            for layer in self.layers:\n",
    "                x = layer(x, y, log_det_J)\n",
    "                self.log_det_J += layer.log_det_J\n",
    "\n",
    "            return x\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, y, log_det_J)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def inverse(self, z: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        # Apply the feature network to y\n",
    "        y = self.h(y)\n",
    "\n",
    "        # Apply the network in reverse\n",
    "        for layer in reversed(self.layers):\n",
    "            z = layer.inverse(z, y)\n",
    "\n",
    "        return z\n",
    "\n",
    "    def sample(self, n_samples: int, y: torch.Tensor, sigma: float = 1, outer: bool = False, verbose: bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample from the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            The number of samples to generate.\n",
    "        y : torch.Tensor\n",
    "            The conditions used for sampling.\n",
    "            If 1st order tensor and len(y) == n_conditions, the same conditions are used for all samples.\n",
    "            If 2nd order tensor, y.shape must be (n_samples, n_conditions), and each row is used as the conditions for each sample.\n",
    "        sigma : float\n",
    "            The standard deviation of the normal distribution to sample from.\n",
    "        outer : bool\n",
    "            If True, the conditions are broadcasted to match the shape of the samples.\n",
    "            If False, the conditions are matched to the shape of the samples.\n",
    "        verbose : bool\n",
    "            If True, print debug information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The generated samples.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f'{y.shape=}')\n",
    "\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            if verbose:\n",
    "                print('Broadcasting')\n",
    "            if len(y) != self.n_conditions:\n",
    "                raise ValueError(f\"y must have length {self.n_conditions}, but got len(y) = {len(y)}\")\n",
    "\n",
    "            # Generate n_samples for each condition in y\n",
    "            z = sigma * torch.randn(n_samples, self.input_size).to(self.device)\n",
    "            y = y.repeat(n_samples, 1)\n",
    "\n",
    "\n",
    "            # Apply the inverse network\n",
    "            return self.inverse(z, y).view(n_samples, self.input_size)\n",
    "        elif y.ndim == 2:\n",
    "            if outer:\n",
    "                if verbose:\n",
    "                    print('Outer')\n",
    "                if y.shape[1] != self.n_conditions:\n",
    "                    raise ValueError(f\"y must have shape (n_samples_per_condition, {self.n_conditions}), but got y.shape = {y.shape}\")\n",
    "\n",
    "                n_samples_per_condition = y.shape[0]\n",
    "\n",
    "                # Generate n_samples for each condition in y\n",
    "                z = sigma * torch.randn(n_samples * n_samples_per_condition, self.input_size).to(self.device)\n",
    "                y = y.repeat(n_samples, 1)\n",
    "\n",
    "                # Apply the inverse network\n",
    "                return self.inverse(z, y).view(n_samples, n_samples_per_condition, self.input_size)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Matching')\n",
    "                if y.shape[0] != n_samples or y.shape[1] != self.n_conditions:\n",
    "                    raise ValueError(f\"y must have shape (n_samples, {self.n_conditions}), but got y.shape = {y.shape}\")\n",
    "        \n",
    "                # Use y_i as the condition for the i-th sample\n",
    "                z = sigma * torch.randn(n_samples, self.input_size).to(self.device)\n",
    "\n",
    "                # Apply the inverse network\n",
    "                return self.inverse(z, y).view(n_samples, self.input_size)\n",
    "        else:\n",
    "            raise ValueError(f\"y must be a 1st or 2nd order tensor, but got y.shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = CondRealNVP(\n",
    "    input_size=2,\n",
    "    hidden_size=256,\n",
    "    n_epochs=8,\n",
    "    n_conditions=7,\n",
    "    feature_network=None,\n",
    "    dropout=0.2,\n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape=torch.Size([7])\n",
      "Broadcasting\n",
      "broadcast_sample.shape=torch.Size([13, 2])\n"
     ]
    }
   ],
   "source": [
    "broadcast_sample = cnf.sample(\n",
    "    n_samples=13,\n",
    "    y=torch.randn(7),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f'{broadcast_sample.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape=torch.Size([13, 7])\n",
      "Matching\n",
      "matching_sample.shape=torch.Size([13, 2])\n"
     ]
    }
   ],
   "source": [
    "matching_sample = cnf.sample(\n",
    "    n_samples=13,\n",
    "    y=torch.randn(13, 7),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f'{matching_sample.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape=torch.Size([5, 7])\n",
      "Outer\n",
      "outer_sample.shape=torch.Size([3, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "outer_sample = cnf.sample(\n",
    "    n_samples=3,\n",
    "    y=torch.randn(5, 7),\n",
    "    outer=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f'{outer_sample.shape=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcnf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
