data:
  converter: "flatten_tensor" # Converter to use for the data of the feature network
  load: False # Load or generate data
  load_path: "./data/bcnf-data/data1.pkl" # Path to the data if it should be loaded
  # Data generation parameters
  name: "data1"
  overwrite: True
  data_generation_config_file: "./configs/config.yaml"
  n_samples: 100
  data_type: "render"
  SPF: 0.5
  T: 3.0
  ratio:
    - 16
    - 9
  fov_horizontal: 70.0
  cam1_pos: 0.0
  print_acc_rej: False
  num_cams: 2
  break_on_impact: False
  verbose: True
model:  # Size is automatically determined by the data size (y)
  tensor_size: "float32"
  nested_sizes:  # List of sizes for the nested network (hidden sizes) first and last layer gets created automatically
    - 240
    - 240
    - 240
  n_blocks: 28 # Number of blocks in the CNF (block = affine coupling layer + orthonormal transformation)
  dropout: 0.23 # Dropout rate (if > 0.0 Dropout layers are inserted after each layer)
  act_norm: True # Some kind of noramlization befor the actication function
  feature_network: # First layer is as big as input
    dropout: 0.13 # Dropout rate (if > 0.0 Dropout layers are inserted after each layer)
    hidden_layer_sizes:
      - 101
      - 101
      - 101
      - 101
    n_conditions: 101 # Size of the outpout of the feature network (Condition size C)
training:
  verify: True # Stop the program and let the user check the model before training
  cross_validation: False  # Use cross-validation
  validation_split: 0.2
  val_loss_alpha: 0.95  # TODO: Find out what this means
  val_loss_tolerance_mode: "rel"
  val_loss_patience: 200
  val_loss_tolerance: 1e-3
  learning_rate: 2e-4
  n_folds: 5  # Number of folds for cross-validation
  shuffle: True  # Shuffle the data using kFold (I think this shuffles it across the folds)
  random_state: 42  # Random state for ??? TODO: Find out for what
  batch_size: 16
  num_workers: 4  # Number of workers for the DataLoader
  pin_memory: True  # Pin memory for the DataLoader
  n_epochs: 100  # Number of epochs to train for using one fold configuration
  verbose: True  # Verbose mode for the training loop
  timeout: 3600  # 1 hour
  wandb:
    model_log_frequency: 10

