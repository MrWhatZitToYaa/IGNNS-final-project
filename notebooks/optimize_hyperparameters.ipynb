{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from bcnf.gp_minimize.gp_minimize import gp_minimize_fixed\n",
    "from bcnf.simulation.physics import get_data\n",
    "from bcnf.models.cnf import CondRealNVP\n",
    "from bcnf.models.feature_network import FullyConnectedFeatureNetwork\n",
    "from bcnf.eval.crossvalidate import cross_validate\n",
    "from bcnf.errors import TrainingDivergedError\n",
    "from bcnf.utils import get_dir\n",
    "\n",
    "from bcnf.simulation.sampling import generate_data\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: scikit-optimize is not maintained anymore and this is a quick fix to make it work\n",
    "# https://github.com/scikit-optimize/scikit-optimize/issues/1171#:~:text=To%20avoid%20this%20error%20in%20existing%20code%2C%20use%20int%20by%20itself.\n",
    "np.int = np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/psaegert/Projects/bcnf/models/bcnf-models/hyperparameter_optimization/stage_2/checkpoint_improved.pkl\n",
      "/home/psaegert/Projects/bcnf/models/bcnf-models/hyperparameter_optimization/stage_2/metrics\n"
     ]
    }
   ],
   "source": [
    "# Store and load the progress in the Huggingface repository\n",
    "checkpoint_file = os.path.join(get_dir(\"models\", \"bcnf-models\", \"hyperparameter_optimization\", \"stage_2\", create=True), 'checkpoint_improved.pkl')\n",
    "metrics_dir = get_dir(\"models\", \"bcnf-models\", \"hyperparameter_optimization\", \"stage_2\", \"metrics\", create=True)\n",
    "\n",
    "print(os.path.abspath(checkpoint_file))\n",
    "print(os.path.abspath(metrics_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['x0_x','x0_y','x0_z','v0_x','v0_y','v0_z','g','w_x','w_y','w_z','b','A','Cd','rho','m','a_x','a_y','a_z','r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"hyperparameter_optimization_trajectories\"\n",
    "\n",
    "# if not os.path.exists(os.path.join(get_dir('data', 'bcnf-data'), dataset_name + '.pkl')):\n",
    "#     data = generate_data(\n",
    "#         n=2000,\n",
    "#         type=\"trajectory\",\n",
    "#         SPF=1/30,\n",
    "#         T=3,\n",
    "#         config_file=os.path.join(get_dir(\"configs\"), \"throw_upwards.yaml\"),\n",
    "#         verbose=True,\n",
    "#         break_on_impact=False,\n",
    "#         name=dataset_name\n",
    "#     )\n",
    "# else:\n",
    "#     with open(os.path.join(get_dir('data', 'bcnf-data'), dataset_name + '.pkl'), 'rb') as f:\n",
    "#         data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(data['traj'])\n",
    "# y = np.column_stack([np.array(data[param]) for param in param_names])\n",
    "\n",
    "\n",
    "# X_tensor = torch.Tensor(X.reshape(X.shape[0], -1))\n",
    "# y_tensor = torch.Tensor(y)\n",
    "\n",
    "# X_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 938.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 90]), torch.Size([2000, 17]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_data(\n",
    "    T=1.0,\n",
    "    dt=1 / 30,\n",
    "    N=2_000,\n",
    "    break_on_impact=False\n",
    ")\n",
    "\n",
    "X_tensor = torch.Tensor(X.reshape(X.shape[0], -1))\n",
    "y_tensor = torch.Tensor(y)\n",
    "\n",
    "X_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 17\n",
      "Feature size: 90\n"
     ]
    }
   ],
   "source": [
    "model_size = y_tensor.shape[1]\n",
    "feature_size = X_tensor.shape[1]\n",
    "\n",
    "print(f\"Model size: {model_size}\")\n",
    "print(f\"Feature size: {feature_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters have worked well in pilot experiments\n",
    "optimizer_kwargs = {\n",
    "    \"lr\": 2e-4\n",
    "}\n",
    "\n",
    "lr_scheduler_kwargs = {\n",
    "    \"mode\": \"min\",\n",
    "    \"factor\": 0.5,\n",
    "    \"patience\": 250,\n",
    "    \"threshold_mode\": \"abs\",\n",
    "    \"threshold\": 1e-1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "search_spaces = {\n",
    "    'condition_size': Integer(1, 2048),\n",
    "    'model_nested_size': Integer(16, 1024),\n",
    "    'model_nested_layers': Integer(1, 8),\n",
    "    'model_n_blocks': Integer(4, 32),\n",
    "    'model_act_norm': Categorical([True, False]),\n",
    "    'model_dropout': Real(0.0, 0.5),\n",
    "    'feature_network_hidden_size': Integer(16, 256),\n",
    "    'feature_network_hidden_layers': Integer(0, 16),\n",
    "    'feature_network_dropout': Real(0.0, 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_index(name: str, search_spaces: dict[str, Real | Integer | Categorical]):\n",
    "    \"\"\"\n",
    "    Get the index of a parameter in the search space to match the order of the parameters in the optimization function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        The name of the parameter.\n",
    "    search_spaces : dict[str, Real | Integer | Categorical]\n",
    "        The search space.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The index of the parameter in the search space.\n",
    "    \"\"\"\n",
    "    return list(search_spaces.keys()).index(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_parameters(params: list):\n",
    "    print({k: v for k, v in zip(search_spaces.keys(), params)})\n",
    "\n",
    "    # Catch training errors (such as divergence) to filter out bad parameter sets and speed up the optimization\n",
    "    try:\n",
    "        # Use cross-validation to estimate the performance of the model\n",
    "        fold_metrics = cross_validate(\n",
    "            model_class=CondRealNVP,\n",
    "            model_kwargs={\n",
    "                \"size\": model_size,\n",
    "                \"nested_sizes\": [params[param_index('model_nested_size', search_spaces)]] * params[param_index('model_nested_layers', search_spaces)],\n",
    "                \"n_blocks\": params[param_index('model_n_blocks', search_spaces)],\n",
    "                \"n_conditions\": params[param_index('condition_size', search_spaces)],\n",
    "                \"act_norm\": params[param_index('model_act_norm', search_spaces)],\n",
    "                \"dropout\": params[param_index('model_dropout', search_spaces)],\n",
    "            },\n",
    "            feature_network_class=FullyConnectedFeatureNetwork,\n",
    "            feature_network_kwargs={\n",
    "                \"sizes\": [feature_size]\n",
    "                    + [params[param_index('feature_network_hidden_size', search_spaces)]] * params[param_index('feature_network_hidden_layers', search_spaces)]\n",
    "                    + [params[param_index('condition_size', search_spaces)]],\n",
    "                \"dropout\": params[param_index('feature_network_dropout', search_spaces)],    \n",
    "            },\n",
    "            optimizer_class=torch.optim.Adam,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            lr_scheduler_class=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "            X=X_tensor,\n",
    "            y=y_tensor,\n",
    "            n_epochs=50_000,\n",
    "            val_loss_patience=500,\n",
    "            val_loss_tolerance=1e-1,  # Improvements to treat as significant\n",
    "            val_loss_tolerance_mode=\"abs\",\n",
    "            timeout=60 * 60,  # 1 hour\n",
    "            batch_size=256,\n",
    "            device=device,\n",
    "            verbose=True,  # Print the progress\n",
    "            n_splits=3,\n",
    "            errors=\"raise\"  # Raise errors to stop the optimization\n",
    "        )\n",
    "\n",
    "        # Save the loss_history and metrics for analysis\n",
    "        with open(os.path.join(metrics_dir, f'params_{\"_\".join([str(p) for p in params])}.pkl'), 'wb') as f:\n",
    "            pickle.dump(fold_metrics, f)\n",
    "\n",
    "    except TrainingDivergedError as e:\n",
    "        print(e)\n",
    "        return 100  # A big number (bad score) to avoid this parameter set\n",
    "\n",
    "    # Print the average validation loss and its standard deviation during optimization\n",
    "    val_loss_list = [r['val_loss'][1] for r in fold_metrics]  # each val_loss value is a tuple (epoch, loss)\n",
    "    print(f'Val Loss: {np.mean(val_loss_list):.4f} ± {np.std(val_loss_list):.4f}')\n",
    "\n",
    "    # Return the upper confidence bound of the validation loss\n",
    "    # This encourages the optimization to find good AND reliable parameter sets\n",
    "    return np.mean(val_loss_list) + np.std(val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(result):\n",
    "    \"\"\"\n",
    "    Save the result of the optimization to a checkpoint file.\n",
    "    Used as a callback in the optimization function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result : OptimizeResult\n",
    "        The result of the optimization.\n",
    "    \"\"\"\n",
    "    # Safely write the result to a temporary file first without overwriting the checkpoint file\n",
    "    with open(checkpoint_file + \".tmp\", 'wb') as f:\n",
    "        # Ignore\n",
    "        # - result['specs']['args']['func']\n",
    "        # - result['specs']['args']['callback']\n",
    "        # because it causes problems when reading somewhere else\n",
    "        result_no_func = copy.deepcopy(result)\n",
    "        del result_no_func['specs']['args']['func']\n",
    "        del result_no_func['specs']['args']['callback']\n",
    "        pickle.dump(result_no_func, f)\n",
    "\n",
    "    # Delete the old checkpoint file and rename the temporary file\n",
    "    shutil.move(checkpoint_file + \".tmp\", checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numer of random initial points to explore the search space\n",
    "N_STEPS_INIT = 30\n",
    "\n",
    "# Number of iterations to run the optimization in total\n",
    "N_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /home/psaegert/Projects/bcnf/models/bcnf-models/hyperparameter_optimization/stage_2/checkpoint_improved.pkl\n",
      "Resuming from iteration 60\n",
      "Running with 0 initial points and 40 remaining iterations\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint if it exists\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f'Loading checkpoint from {checkpoint_file}')\n",
    "\n",
    "    with open(checkpoint_file, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "\n",
    "        # Re-assign the function and callback because they are not picklable\n",
    "        checkpoint['specs']['args']['func'] = score_parameters\n",
    "        checkpoint['specs']['args']['callback'] = save_checkpoint\n",
    "\n",
    "    print(f'Resuming from iteration {len(checkpoint.x_iters)}')\n",
    "\n",
    "    n_initial_points = max(0, N_STEPS_INIT - len(checkpoint.x_iters))\n",
    "    n_calls_remaining = max(0, N_STEPS - len(checkpoint.x_iters))\n",
    "    x0 = checkpoint.x_iters\n",
    "    y0 = checkpoint.func_vals\n",
    "else:\n",
    "    print('No checkpoint found. Starting new optimization')\n",
    "    checkpoint = None\n",
    "\n",
    "    n_initial_points = N_STEPS_INIT\n",
    "    n_calls_remaining = N_STEPS\n",
    "\n",
    "    x0 = None\n",
    "    y0 = None\n",
    "    \n",
    "print(f'Running with {n_initial_points} initial points and {n_calls_remaining} remaining iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 initial points will be randomly generated\n",
      "Iteration No: 1 started. Searching for the next optimal point.\n",
      "Telling optimizer about 60 initial points\n",
      "Iteration No: 1 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9767\n",
      "Function value obtained: -18.6476\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 2 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 1: [992, 25, 8, 27, True, 0.0, 87, 7, 0.3220522680512488]\n",
      "{'condition_size': 992, 'model_nested_size': 25, 'model_nested_layers': 8, 'model_n_blocks': 27, 'model_act_norm': True, 'model_dropout': 0.0, 'feature_network_hidden_size': 87, 'feature_network_hidden_layers': 7, 'feature_network_dropout': 0.3220522680512488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -47.0810 - Val: -48.2658 (avg: -48.2620, min: -48.1994) | lr: 3.91e-07 - Patience: 500/500:  23%|██▎       | 11739/50000 [51:55<2:49:13,  3.77it/s]\n",
      "Train: -44.6245 - Val: -45.4706 (avg: -45.4670, min: -45.3916) | lr: 3.91e-07 - Patience: 500/500:  25%|██▍       | 12426/50000 [54:13<2:43:56,  3.82it/s]\n",
      "Train: -45.9818 - Val: -46.6818 (avg: -46.6778, min: -46.6211) | lr: 3.91e-07 - Patience: 500/500:  26%|██▌       | 13015/50000 [58:15<2:45:32,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: -46.7953 ± 1.1835\n",
      "Iteration No: 2 ended. Search finished for the next optimal point.\n",
      "Time taken: 9864.8863\n",
      "Function value obtained: -45.6119\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 3 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 2: [836, 191, 7, 21, True, 0.0, 159, 5, 0.37867605407596466]\n",
      "{'condition_size': 836, 'model_nested_size': 191, 'model_nested_layers': 7, 'model_n_blocks': 21, 'model_act_norm': True, 'model_dropout': 0.0, 'feature_network_hidden_size': 159, 'feature_network_hidden_layers': 5, 'feature_network_dropout': 0.37867605407596466}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -46.1406 - Val: -39.7691 (avg: -39.7616, min: -39.6890) | lr: 7.81e-07 - Patience: 500/500:  15%|█▍        | 7265/50000 [23:38<2:19:05,  5.12it/s]\n",
      "Train: -46.5826 - Val: -35.9967 (avg: -36.0123, min: -35.9978) | lr: 1.56e-06 - Patience: 500/500:  11%|█         | 5555/50000 [18:06<2:24:56,  5.11it/s]\n",
      "Train: -44.7416 - Val: -34.1657 (avg: -34.2247, min: -34.3619) | lr: 1.25e-05 - Patience: 500/500:  10%|▉         | 4990/50000 [16:15<2:26:42,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: -36.9045 ± 3.2040\n",
      "Iteration No: 3 ended. Search finished for the next optimal point.\n",
      "Time taken: 3482.3498\n",
      "Function value obtained: -33.7005\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 4 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 3: [236, 168, 7, 19, True, 0.0, 76, 7, 0.2690183822722158]\n",
      "{'condition_size': 236, 'model_nested_size': 168, 'model_nested_layers': 7, 'model_n_blocks': 19, 'model_act_norm': True, 'model_dropout': 0.0, 'feature_network_hidden_size': 76, 'feature_network_hidden_layers': 7, 'feature_network_dropout': 0.2690183822722158}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -56.0712 - Val: -54.4187 (avg: -54.4273, min: -54.3768) | lr: 1.95e-07 - Patience: 500/500:  32%|███▏      | 15810/50000 [47:19<1:42:20,  5.57it/s]\n",
      "Train: -52.0603 - Val: -50.8125 (avg: -50.8089, min: -50.7452) | lr: 1.95e-07 - Patience: 500/500:  26%|██▌       | 12903/50000 [38:33<1:50:52,  5.58it/s]\n",
      "Train: -52.1621 - Val: -50.8654 (avg: -50.8645, min: -50.8004) | lr: 1.95e-07 - Patience: 500/500:  28%|██▊       | 13886/50000 [43:17<1:52:34,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: -52.1213 ± 1.8443\n",
      "Iteration No: 4 ended. Search finished for the next optimal point.\n",
      "Time taken: 7751.5911\n",
      "Function value obtained: -50.2770\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 5 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 4: [1, 657, 1, 32, True, 0.0, 62, 7, 0.37963881520371445]\n",
      "{'condition_size': 1, 'model_nested_size': 657, 'model_nested_layers': 1, 'model_n_blocks': 32, 'model_act_norm': True, 'model_dropout': 0.0, 'feature_network_hidden_size': 62, 'feature_network_hidden_layers': 7, 'feature_network_dropout': 0.37963881520371445}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in fold 0: Loss exploded to 328494350336.0 at epoch 0.0\n",
      "Loss exploded to 328494350336.0 at epoch 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 5 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.0400\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 5: [1411, 16, 6, 23, True, 0.3496986851458296, 115, 11, 0.0010641263107296934]\n",
      "{'condition_size': 1411, 'model_nested_size': 16, 'model_nested_layers': 6, 'model_n_blocks': 23, 'model_act_norm': True, 'model_dropout': 0.3496986851458296, 'feature_network_hidden_size': 115, 'feature_network_hidden_layers': 11, 'feature_network_dropout': 0.0010641263107296934}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -52.0266 - Val: -52.8889 (avg: -52.9086, min: -52.8413) | lr: 1.56e-06 - Patience: 500/500:  24%|██▍       | 11964/50000 [45:48<2:25:39,  4.35it/s]\n",
      "Train: -48.4260 - Val: -49.9164 (avg: -49.8990, min: -49.8183) | lr: 1.56e-06 - Patience: 500/500:  25%|██▌       | 12748/50000 [47:29<2:18:47,  4.47it/s]\n",
      "Train: -49.6580 - Val: -51.6053 (avg: -51.6053, min: -51.5341) | lr: 1.56e-06 - Patience: 500/500:  23%|██▎       | 11515/50000 [42:01<2:20:28,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: -51.2800 ± 0.8348\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 8121.4169\n",
      "Function value obtained: -50.4452\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 6: [756, 16, 5, 32, True, 0.10481498527421296, 148, 8, 0.49711776274068753]\n",
      "{'condition_size': 756, 'model_nested_size': 16, 'model_nested_layers': 5, 'model_n_blocks': 32, 'model_act_norm': True, 'model_dropout': 0.10481498527421296, 'feature_network_hidden_size': 148, 'feature_network_hidden_layers': 8, 'feature_network_dropout': 0.49711776274068753}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -47.4716 - Val: -49.1153 (avg: -49.1210, min: -49.0415) | lr: 7.81e-07 - Patience: 500/500:  20%|██        | 10246/50000 [45:43<2:57:24,  3.73it/s]\n",
      "Train: -48.8747 - Val: -49.8631 (avg: -49.8732, min: -49.7903) | lr: 1.56e-06 - Patience: 500/500:  25%|██▌       | 12707/50000 [57:49<2:49:43,  3.66it/s]\n",
      "Train: -48.1746 - Val: -49.7327 (avg: -49.7265, min: -49.6355) | lr: 7.81e-07 - Patience: 500/500:  21%|██▏       | 10712/50000 [46:59<2:52:21,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: -49.4777 ± 0.3163\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 9035.0300\n",
      "Function value obtained: -49.1614\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 7: [912, 290, 6, 18, True, 0.1478576853436927, 137, 7, 0.5]\n",
      "{'condition_size': 912, 'model_nested_size': 290, 'model_nested_layers': 6, 'model_n_blocks': 18, 'model_act_norm': True, 'model_dropout': 0.1478576853436927, 'feature_network_hidden_size': 137, 'feature_network_hidden_layers': 7, 'feature_network_dropout': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 4.3147 - Val: 1237.8316 (avg: 30.4067, min: -33.7473) | lr: 2.00e-04 - Patience: 42/500:   9%|▉         | 4464/50000 [14:03<2:23:21,  5.29it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in fold 0: Loss exploded to 155130.265625 at epoch 4464.166666666667\n",
      "Loss exploded to 155130.265625 at epoch 4464.166666666667\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 844.9519\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 8: [288, 16, 2, 23, True, 0.07146908809713125, 114, 9, 0.3589314349977031]\n",
      "{'condition_size': 288, 'model_nested_size': 16, 'model_nested_layers': 2, 'model_n_blocks': 23, 'model_act_norm': True, 'model_dropout': 0.07146908809713125, 'feature_network_hidden_size': 114, 'feature_network_hidden_layers': 9, 'feature_network_dropout': 0.3589314349977031}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -47.8907 - Val: -49.6865 (avg: -49.6816, min: -49.6296) | lr: 7.81e-07 - Patience: 500/500:  23%|██▎       | 11650/50000 [28:25<1:33:33,  6.83it/s]\n",
      "Train: -47.7180 - Val: -49.7188 (avg: -49.6879, min: -49.6388) | lr: 7.81e-07 - Patience: 500/500:  26%|██▌       | 12968/50000 [32:09<1:31:50,  6.72it/s]\n",
      "Train: -6.7625 - Val: -7.1735 (avg: -7.2033, min: -7.2048) | lr: 2.00e-04 - Patience: 1/500:   1%|          | 262/50000 [00:38<2:02:42,  6.76it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in fold 2: Loss exploded to 684353.375 at epoch 262.5\n",
      "Loss exploded to 684353.375 at epoch 262.5\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 3675.5881\n",
      "Function value obtained: 100.0000\n",
      "Current minimum: -57.6940\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Asking optimizer for next point 9: [1241, 129, 3, 32, True, 0.2615379899589816, 67, 7, 0.1750433289775834]\n",
      "{'condition_size': 1241, 'model_nested_size': 129, 'model_nested_layers': 3, 'model_n_blocks': 32, 'model_act_norm': True, 'model_dropout': 0.2615379899589816, 'feature_network_hidden_size': 67, 'feature_network_hidden_layers': 7, 'feature_network_dropout': 0.1750433289775834}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: -47.7770 - Val: -50.7355 (avg: -50.7271, min: -50.7191) | lr: 7.81e-07 - Patience: 185/500:  21%|██        | 10340/50000 [40:16<2:38:23,  4.17it/s]"
     ]
    }
   ],
   "source": [
    "# You might want to adjust the n_calls or other parameters based on the checkpoint\n",
    "result = gp_minimize_fixed(\n",
    "    func=score_parameters,\n",
    "    dimensions=search_spaces.values(),\n",
    "    n_initial_points=n_initial_points,  # Number of random points before starting the optimization\n",
    "    n_calls=n_calls_remaining,  # Number of iterations\n",
    "    random_state=2024_03_25,\n",
    "    verbose=True,\n",
    "    acq_func=\"EI\",  # Expected Improvement https://arxiv.org/pdf/1009.5419.pdf\n",
    "    initial_point_generator=\"halton\", # https://en.wikipedia.org/wiki/Halton_sequence\n",
    "    callback=save_checkpoint,\n",
    "    x0=x0,\n",
    "    y0=y0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcnf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
